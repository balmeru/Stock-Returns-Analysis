{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c816de6-67d3-4853-a113-255ff68f4ac4",
   "metadata": {},
   "source": [
    "\n",
    "<p style=\"font-size:21px; font-family:'Times New Roman';\">\n",
    "Read report dates data \n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "afee8605-6296-4589-abee-6cb79cadc57f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "csv_file_path = '/Users/balmeru/Downloads/QQQQ.csv'\n",
    "df = pd.read_csv(csv_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c6af95d8-4487-407d-84fb-0077d34854c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['market_cap'] = df['prccq'] / df['ajexq'] * df['cshoq']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d69a9f77-4cc8-45c8-bd14-5eb734113460",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   prccq  ajexq  cshoq  market_cap\n",
      "0  2.875    1.0  2.092     6.01450\n",
      "1  4.000    1.0  2.094     8.37600\n",
      "2  4.375    1.0  2.098     9.17875\n",
      "3  6.750    1.0  2.096    14.14800\n",
      "4  7.250    1.0  2.163    15.68175\n"
     ]
    }
   ],
   "source": [
    "print(df[['prccq', 'ajexq', 'cshoq', 'market_cap']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad2f33a5-8259-4b57-9929-999f2f5e84a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate upper and lower bounds\n",
    "df['lower_bound'] = 0.8 * df['market_cap']\n",
    "df['upper_bound'] = 1.2 * df['market_cap']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "572d65b0-aec9-42f4-a7cf-61af9bdcf020",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['quarterly_report'] = (df['fqtr'].isin([1, 2, 3])).astype(int)\n",
    "df['annual_report'] = (df['fqtr'] == 4).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ab8791d-1ca9-4297-b6dd-68658ab24e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['fyr'] = pd.to_numeric(df['fyr'], errors='coerce')\n",
    "df = df.sort_values(by=['tic', 'fyearq', 'fqtr'])\n",
    "ticker_change = df['tic'] != df['tic'].shift(1)\n",
    "df['fyr_change_dummy'] = ((df['fyr'] != df['fyr'].shift(1)) & (~ticker_change)).astype(int)\n",
    "\n",
    "# Fill the first occurrence of each ticker group with 0\n",
    "df.loc[df.groupby('tic').head(1).index, 'fyr_change_dummy'] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6696c261-f038-4c2b-93cb-3dc089deb8c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ds/rfyxvvb945vdt8znlkx31w1m00cj2y/T/ipykernel_17600/1492790700.py:32: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df = grouped.apply(calculate_diff)\n"
     ]
    }
   ],
   "source": [
    "df['rdq'] = pd.to_datetime(df['rdq'], errors='coerce')\n",
    "df['fyearq'] = pd.to_numeric(df['fyearq'], errors='coerce')\n",
    "df['fqtr'] = pd.to_numeric(df['fqtr'], errors='coerce')\n",
    "\n",
    "grouped = df.groupby('tic', group_keys=False)\n",
    "\n",
    "# Function to calculate consecutive differences\n",
    "def calculate_diff(group):\n",
    "    # Sort the data within each group by the fiscal year and quarter in ascending order\n",
    "    group = group.sort_values(['fyearq', 'fqtr'])\n",
    "    \n",
    "    # Create a shifted column for the previous rdq\n",
    "    group['prev_rdq'] = group['rdq'].shift(1)\n",
    "    group['prev_fqtr'] = group['fqtr'].shift(1)\n",
    "    group['prev_fyearq'] = group['fyearq'].shift(1)\n",
    "    \n",
    "    # Calculate the differences\n",
    "    group['diff'] = group['rdq'] - group['prev_rdq']\n",
    "    \n",
    "    # Remove differences where quarters and years are not consecutive\n",
    "    mask = (group['fqtr'] == 1) & (group['prev_fqtr'] == 4) & (group['fyearq'] == group['prev_fyearq'] + 1)\n",
    "    mask |= (group['fqtr'] > 1) & (group['fqtr'] == group['prev_fqtr'] + 1) & (group['fyearq'] == group['prev_fyearq'])\n",
    "    \n",
    "    group['diff'] = group['diff'].where(mask)\n",
    "    \n",
    "    # Drop helper columns\n",
    "    group = group.drop(columns=['prev_rdq', 'prev_fqtr', 'prev_fyearq'])\n",
    "    \n",
    "    return group\n",
    "\n",
    "# Apply the function to each ticker group directly in the original DataFrame\n",
    "df = grouped.apply(calculate_diff)\n",
    "df.loc[df['fyr_change_dummy'] == 1, 'diff'] = pd.NaT\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d278333-a352-4d67-aeb1-72a769395c97",
   "metadata": {},
   "source": [
    "#### Let's split the distance for quarterly and annual reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d7ec9ae8-3d3d-4788-852d-9bda850b1e1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     tic        rdq  fyr  fyearq  fqtr  fyr_change_dummy annual_distance  \\\n",
      "0  0015B        NaT   10    1983     3                 0             NaT   \n",
      "1  0015B 1984-01-16   10    1983     4                 0             NaT   \n",
      "2  0015B 1984-03-15   10    1984     1                 0             NaT   \n",
      "3  0015B 1984-05-25   10    1984     2                 0             NaT   \n",
      "4  0015B 1984-08-27   10    1984     3                 0             NaT   \n",
      "\n",
      "  quarter_distance    diff  \n",
      "0              NaT     NaT  \n",
      "1              NaT     NaT  \n",
      "2          59 days 59 days  \n",
      "3          71 days 71 days  \n",
      "4          94 days 94 days  \n"
     ]
    }
   ],
   "source": [
    "df['quarter_distance'] = df['diff'].where(df['quarterly_report'] == 1, pd.NaT)\n",
    "df['annual_distance'] = df['diff'].where(df['annual_report'] == 1, pd.NaT)\n",
    "print(df[['tic', 'rdq', 'fyr', 'fyearq', 'fqtr', 'fyr_change_dummy', 'annual_distance', 'quarter_distance', 'diff']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d41947a1-2f8f-48cb-b7b2-f8e802ed93bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of instances with all empty distances: 413\n",
      "Number of instances with non-empty distances: 1775\n",
      "Number of unique tickers with non-empty distances: 1568\n",
      "Number of unique tickers with all empty distances: 363\n",
      "Number of unique tickers with mixed distances: 47\n",
      "Total number of unique tickers with fiscal year changes: 1978\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Initialize the 'median_distance' column with NaN values\n",
    "df['median_distance'] = np.nan\n",
    "\n",
    "# Ensure the 'median_distance' column is updated for fiscal year change rows\n",
    "df['median_distance'] = np.where(df['fyr_change_dummy'] == 0, np.nan, df['median_distance'])\n",
    "\n",
    "# Initialize variables to count instances with all empty and non-empty distances\n",
    "num_instances_all_empty = 0\n",
    "num_instances_non_empty = 0\n",
    "\n",
    "# Initialize sets to store tickers with non-empty, empty, and mixed distances\n",
    "non_empty_distances_tickers = set()\n",
    "empty_distances_tickers = set()\n",
    "mixed_distances_tickers = set()\n",
    "\n",
    "# Filter rows where fiscal year change occurred\n",
    "fyr_change_rows = df[df['fyr_change_dummy'] == 1]\n",
    "\n",
    "# Iterate over rows where fiscal year change occurred\n",
    "for index, fyr_change_row in fyr_change_rows.iterrows():\n",
    "    # Determine if it's a quarterly or annual report\n",
    "    is_quarterly_report = fyr_change_row['quarterly_report'] == 1\n",
    "\n",
    "    # Filter similar market cap tickers excluding own ticker\n",
    "    similar_cap_tickers = df[(df['market_cap'] >= fyr_change_row['lower_bound']) &\n",
    "                             (df['market_cap'] <= fyr_change_row['upper_bound']) &\n",
    "                             (df['tic'] != fyr_change_row['tic'])]\n",
    "\n",
    "    # Determine relevant distance column and filter criteria\n",
    "    distance_col = 'quarter_distance' if is_quarterly_report else 'annual_distance'\n",
    "    year_col = 'fyearq'\n",
    "    years = [fyr_change_row['fyearq'], fyr_change_row['fyearq'] + 1, fyr_change_row['fyearq'] - 1]\n",
    "\n",
    "    # Extract distances\n",
    "    distances = similar_cap_tickers[similar_cap_tickers[year_col].isin(years)][distance_col].dropna().apply(lambda x: pd.Timedelta(x).days)\n",
    "\n",
    "    # Check if distances list is empty\n",
    "    if distances.empty:\n",
    "        num_instances_all_empty += 1\n",
    "        if fyr_change_row['tic'] in non_empty_distances_tickers:\n",
    "            mixed_distances_tickers.add(fyr_change_row['tic'])\n",
    "        else:\n",
    "            empty_distances_tickers.add(fyr_change_row['tic'])\n",
    "    else:\n",
    "        median_distance = distances.median()\n",
    "        df.loc[index, 'median_distance'] = median_distance\n",
    "        num_instances_non_empty += 1\n",
    "        if fyr_change_row['tic'] in empty_distances_tickers:\n",
    "            mixed_distances_tickers.add(fyr_change_row['tic'])\n",
    "        else:\n",
    "            non_empty_distances_tickers.add(fyr_change_row['tic'])\n",
    "\n",
    "# Calculate counts for unique tickers\n",
    "num_non_empty_distances_tickers = len(non_empty_distances_tickers - mixed_distances_tickers)\n",
    "num_empty_distances_tickers = len(empty_distances_tickers - mixed_distances_tickers)\n",
    "num_mixed_distances_tickers = len(mixed_distances_tickers)\n",
    "num_unique_fyr_change_tickers = fyr_change_rows['tic'].nunique()\n",
    "\n",
    "# Display the results\n",
    "print(f\"Number of instances with all empty distances: {num_instances_all_empty}\")\n",
    "print(f\"Number of instances with non-empty distances: {num_instances_non_empty}\")\n",
    "print(f\"Number of unique tickers with non-empty distances: {num_non_empty_distances_tickers}\")\n",
    "print(f\"Number of unique tickers with all empty distances: {num_empty_distances_tickers}\")\n",
    "print(f\"Number of unique tickers with mixed distances: {num_mixed_distances_tickers}\")\n",
    "print(f\"Total number of unique tickers with fiscal year changes: {num_unique_fyr_change_tickers}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "510bfbe9-16dc-4d3d-a44f-7d279e36ee0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8dd07ef7-dd0d-4855-adfe-7f3cf61b72a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter rows where fiscal year change occurred\n",
    "fyr_change_rows = df[df['fyr_change_dummy'] == 1]\n",
    "\n",
    "# Iterate over rows where fiscal year change occurred\n",
    "for index, fyr_change_row in fyr_change_rows.iterrows():\n",
    "    # Check if fiscal year change happened in quarterly or annual report\n",
    "    is_quarterly_report = fyr_change_row['quarterly_report'] == 1\n",
    "\n",
    "    # Determine which column to assign median distance\n",
    "    median_distance_column = 'annual_median' if not is_quarterly_report else 'quarterly_median'\n",
    "\n",
    "    # Update the median_distance column accordingly\n",
    "    df.loc[index, median_distance_column] = fyr_change_row['median_distance']\n",
    "\n",
    "# Set NaN for rows where fyr_change_dummy is 0\n",
    "df.loc[df['fyr_change_dummy'] == 0, ['annual_median', 'quarterly_median']] = np.nan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d9b3063c-c983-4a40-a08e-41c164d30749",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    1775.00\n",
      "mean       90.70\n",
      "std         4.69\n",
      "min        68.00\n",
      "25%        90.00\n",
      "50%        90.00\n",
      "75%        91.00\n",
      "max       132.00\n",
      "Name: median_distance, dtype: object\n"
     ]
    }
   ],
   "source": [
    "summary_stats = df['median_distance'].describe()\n",
    "formatted_stats = summary_stats.apply(lambda x: f'{x:.2f}')\n",
    "\n",
    "print(formatted_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f1102b-a6c5-4fd2-9577-45cefc8bd9dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8d878b7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    1775.00\n",
      "mean       90.70\n",
      "std         4.69\n",
      "min        68.00\n",
      "25%        90.00\n",
      "50%        90.00\n",
      "75%        91.00\n",
      "max       132.00\n",
      "Name: median_distance, dtype: object\n"
     ]
    }
   ],
   "source": [
    "summary_stats = df['median_distance'].describe()\n",
    "formatted_stats = summary_stats.apply(lambda x: f'{x:.2f}')\n",
    "\n",
    "print(formatted_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "31c0d373-272a-417a-baea-05d8c41dae2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary statistics for Annual Median:\n",
      "count     55.000000\n",
      "mean     115.045455\n",
      "std        6.437213\n",
      "min      101.000000\n",
      "25%      112.000000\n",
      "50%      116.000000\n",
      "75%      119.000000\n",
      "max      132.000000\n",
      "Name: annual_median, dtype: float64\n",
      "\n",
      "Summary statistixcs for Quarterly Median:\n",
      "count    1720.000000\n",
      "mean       89.922965\n",
      "std         1.337046\n",
      "min        68.000000\n",
      "25%        90.000000\n",
      "50%        90.000000\n",
      "75%        91.000000\n",
      "max        91.000000\n",
      "Name: quarterly_median, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "annual_median_summary = df['annual_median'].describe()\n",
    "print(\"Summary statistics for Annual Median:\")\n",
    "print(annual_median_summary)\n",
    "\n",
    "quarterly_median_summary = df['quarterly_median'].describe()\n",
    "print(\"\\nSummary statistixcs for Quarterly Median:\")\n",
    "print(quarterly_median_summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a91ee9f0-7aae-4128-a9b3-b09a076c98ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "59c9b9f5-78ec-4685-9222-a870744dd202",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    1775.00\n",
      "mean       90.70\n",
      "std         4.69\n",
      "min        68.00\n",
      "25%        90.00\n",
      "50%        90.00\n",
      "75%        91.00\n",
      "max       132.00\n",
      "Name: median_distance, dtype: object\n"
     ]
    }
   ],
   "source": [
    "summary_stats = df['median_distance'].describe()\n",
    "formatted_stats = summary_stats.apply(lambda x: f'{x:.2f}')\n",
    "\n",
    "print(formatted_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55886d84-a06d-4f99-959e-e4f1d7fba394",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b25cb724-4051-4478-8311-65bdebb8d282",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a9905736-5d79-4752-8b0f-607ebfde13e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of entries where fyr_change_dummy == 1 and market_cap is empty: 411\n"
     ]
    }
   ],
   "source": [
    "filtered_df = df[(df['fyr_change_dummy'] == 1) & (df['market_cap'].isna())]\n",
    "num_entries = len(filtered_df)\n",
    "\n",
    "print(f'Number of entries where fyr_change_dummy == 1 and market_cap is empty: {num_entries}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a0b8061-8f86-4369-b0ad-5607dfde97a0",
   "metadata": {},
   "source": [
    "#### As we see instances which had fyr change, 411 cases had empty market_caps. It means 411 out of 413 median distances that \n",
    "#### are uncalculated was due to **missing market_cap**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d492cc5-0a86-4cf1-88fe-731c7ea1beab",
   "metadata": {},
   "source": [
    "#### We will find cshoq to be proportional value between its last and next reported values, otherwise it is reasonable that we can't calculate median distances. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "11a61c0c-8e45-46f8-9034-7d74d7ecdd90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of entries where fyr_change_dummy == 1 and cshoq is empty: 393\n"
     ]
    }
   ],
   "source": [
    "filtered_df = df[(df['fyr_change_dummy'] == 1) & (df['cshoq'].isna())]\n",
    "num_entries = len(filtered_df)\n",
    "\n",
    "print(f'Number of entries where fyr_change_dummy == 1 and cshoq is empty: {num_entries}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3c83aeab-248f-4067-b2a3-2a28f091a09d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows with fiscal year change and 'prccq' missing: 28\n"
     ]
    }
   ],
   "source": [
    "filtered_rows = df[(df['fyr_change_dummy'] == 1) & df['prccq'].isna()]\n",
    "print(f\"Number of rows with fiscal year change and 'prccq' missing: {len(filtered_rows)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1e01f43-cab4-4eef-aff3-403802558441",
   "metadata": {},
   "source": [
    "#### 411 of 413 is due to missing market_cap, out of which 393 is due to cshoq absence, 28 is from price 'prccq' absense. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a42c20-9f5c-491d-8023-bc946609a331",
   "metadata": {},
   "source": [
    "#### For now we will relieve this 28 missing price cases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b84ed3a2-ef2c-4f2c-ad51-ca177ebe6de0",
   "metadata": {},
   "source": [
    "#### Now we will look for one above and below non-empty 'cshoq'. Determining which year and quarter found cshoqs belong to, we calculate the proportionate cshoq where it's missing\n",
    "#### Example: Missing cshoq is 2024 Q1, above non-empty cshoq 2023 Q4 = 7, below 2024 Q2 =8, then we fill in with 7.5\n",
    "#### Missing cshoq is 2024 Q2, above non-empty cshoq 2024 Q2 = 1, below 2024 Q4 =2, then we fill in with 1.33. \n",
    "#### If above and below non-empty cshoqs are the same, then our cshoq is equal to that value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aecd4b19-abfc-4232-afb5-a179672506c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ds/rfyxvvb945vdt8znlkx31w1m00cj2y/T/ipykernel_17600/4092613696.py:20: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '1988Q4' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[index, 'above_datafqtr'] = above_row['datafqtr']\n",
      "/var/folders/ds/rfyxvvb945vdt8znlkx31w1m00cj2y/T/ipykernel_17600/4092613696.py:28: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '1989Q4' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[index, 'below_datafqtr'] = below_row['datafqtr']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          GVKEY    datadate  fyearq  fqtr  fyr indfmt consol popsrc datafmt  \\\n",
      "22         2484  1988-09-30    1989     1    6   INDL      C      D     STD   \n",
      "1078      23929  1996-12-31    1997     1    9   INDL      C      D     STD   \n",
      "2993       6726  1979-12-31    1980     1    9   INDL      C      D     STD   \n",
      "3289       3688  1980-09-30    1981     1    6   INDL      C      D     STD   \n",
      "3821      14287  1990-03-31    1990     1   12   INDL      C      D     STD   \n",
      "...         ...         ...     ...   ...  ...    ...    ...    ...     ...   \n",
      "1072221   18484  1994-11-30    1995     1    8   INDL      C      D     STD   \n",
      "1075104   24318  1999-03-31    1999     1   12   INDL      C      D     STD   \n",
      "1075351  100598  2000-03-31    2000     1   12   INDL      C      D     STD   \n",
      "1076701   30751  1997-03-31    1997     1   12   INDL      C      D     STD   \n",
      "1080188   11656  1991-05-31    1991     1    2   INDL      C      D     STD   \n",
      "\n",
      "            tic  ...  diff quarter_distance annual_distance median_distance  \\\n",
      "22        0015B  ...   NaT              NaT             NaT             NaN   \n",
      "1078      0147A  ...   NaT              NaT             NaT             NaN   \n",
      "2993      2788A  ...   NaT              NaT             NaT             NaN   \n",
      "3289      2919B  ...   NaT              NaT             NaT             NaN   \n",
      "3821      3213B  ...   NaT              NaT             NaT             NaN   \n",
      "...         ...  ...   ...              ...             ...             ...   \n",
      "1072221  WWWW.1  ...   NaT              NaT             NaT             NaN   \n",
      "1075104    XL.1  ...   NaT              NaT             NaT             NaN   \n",
      "1075351     XLL  ...   NaT              NaT             NaT             NaN   \n",
      "1076701   XPRSA  ...   NaT              NaT             NaT             NaN   \n",
      "1080188    YORK  ...   NaT              NaT             NaT             NaN   \n",
      "\n",
      "        quarterly_median  annual_median  above_cshoq  below_cshoq  \\\n",
      "22                   NaN            NaN       11.762       11.808   \n",
      "1078                 NaN            NaN        6.548        6.555   \n",
      "2993                 NaN            NaN        8.436        8.458   \n",
      "3289                 NaN            NaN        3.126        3.126   \n",
      "3821                 NaN            NaN       71.085       71.345   \n",
      "...                  ...            ...          ...          ...   \n",
      "1072221              NaN            NaN        8.804       91.422   \n",
      "1075104              NaN            NaN      111.804      127.580   \n",
      "1075351              NaN            NaN      104.860          NaN   \n",
      "1076701              NaN            NaN       12.086       12.117   \n",
      "1080188              NaN            NaN        8.477        9.148   \n",
      "\n",
      "         above_datafqtr  below_datafqtr  \n",
      "22               1988Q4          1989Q4  \n",
      "1078             1996Q4          1997Q2  \n",
      "2993             1979Q4          1980Q2  \n",
      "3289             1980Q4          1981Q3  \n",
      "3821             1989Q4          1990Q4  \n",
      "...                 ...             ...  \n",
      "1072221          1994Q4          1995Q3  \n",
      "1075104          1998Q4          1999Q3  \n",
      "1075351          1999Q4             NaN  \n",
      "1076701          1996Q4          1997Q2  \n",
      "1080188          1990Q4          1991Q3  \n",
      "\n",
      "[393 rows x 45 columns]\n"
     ]
    }
   ],
   "source": [
    "# Initialize above_cshoq, below_cshoq, above_datafqtr, and below_datafqtr as NaN\n",
    "df['above_cshoq'] = np.nan\n",
    "df['below_cshoq'] = np.nan\n",
    "df['above_datafqtr'] = np.nan\n",
    "df['below_datafqtr'] = np.nan\n",
    "\n",
    "# Find rows where fyr_change_dummy is 1 and cshoq is NaN\n",
    "missing_cshoq_indices = df[(df['fyr_change_dummy'] == 1) & df['cshoq'].isna()].index\n",
    "\n",
    "# Iterate over the missing cshoq indices to find above_cshoq, below_cshoq, above_datafqtr, and below_datafqtr\n",
    "for index in missing_cshoq_indices:\n",
    "    tic = df.at[index, 'tic']\n",
    "    current_datafqtr = df.at[index, 'datafqtr']\n",
    "    \n",
    "    # Find the row above with a non-missing cshoq value\n",
    "    above_rows = df[(df['tic'] == tic) & (df['datafqtr'] < current_datafqtr)].sort_values(by='datafqtr', ascending=False)\n",
    "    for _, above_row in above_rows.iterrows():\n",
    "        if not pd.isna(above_row['cshoq']):\n",
    "            df.at[index, 'above_cshoq'] = above_row['cshoq']\n",
    "            df.at[index, 'above_datafqtr'] = above_row['datafqtr']\n",
    "            break\n",
    "    \n",
    "    # Find the row below with a non-missing cshoq value\n",
    "    below_rows = df[(df['tic'] == tic) & (df['datafqtr'] > current_datafqtr)].sort_values(by='datafqtr', ascending=True)\n",
    "    for _, below_row in below_rows.iterrows():\n",
    "        if not pd.isna(below_row['cshoq']):\n",
    "            df.at[index, 'below_cshoq'] = below_row['cshoq']\n",
    "            df.at[index, 'below_datafqtr'] = below_row['datafqtr']\n",
    "            break\n",
    "\n",
    "# Print rows where fyr_change_dummy is 1 and cshoq is NaN\n",
    "print(df[(df['fyr_change_dummy'] == 1) & df['cshoq'].isna()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8207186e-a5be-4a69-9365-faec3245b8c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows where both above_cshoq and below_cshoq are not  NaN: 371\n"
     ]
    }
   ],
   "source": [
    "filtered_df = df[(df['fyr_change_dummy'] == 1) & \n",
    "                 df['cshoq'].isna() & \n",
    "                 df['above_cshoq'].notna() & \n",
    "                 df['below_cshoq'].notna()]\n",
    "count_both_na = filtered_df.shape[0]\n",
    "print(\"Number of rows where both above_cshoq and below_cshoq are not  NaN:\", count_both_na)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c2f5c220-dde8-4f38-ba77-abf023e47f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['diff_fqtr'] = np.nan\n",
    "\n",
    "# Calculate diff_fqtr for rows where both below_datafqtr and above_datafqtr are given\n",
    "mask = (df['fyr_change_dummy'] == 1) & df['cshoq'].isna() & df['below_datafqtr'].notna() & df['above_datafqtr'].notna()\n",
    "\n",
    "for index, row in df[mask].iterrows():\n",
    "    # Extract year and quarter from below_datafqtr and above_datafqtr\n",
    "    below_year, below_quarter = row['below_datafqtr'].split('Q')\n",
    "    above_year, above_quarter = row['above_datafqtr'].split('Q')\n",
    "\n",
    "    # Convert year and quarter to integers\n",
    "    below_year = int(below_year)\n",
    "    below_quarter = int(below_quarter)\n",
    "    above_year = int(above_year)\n",
    "    above_quarter = int(above_quarter)\n",
    "\n",
    "    # Calculate the difference in quarters\n",
    "    diff_fqtr = (below_year - above_year) * 4 + (below_quarter - above_quarter)\n",
    "\n",
    "    # Update the diff_fqtr column with the calculated difference\n",
    "    df.at[index, 'diff_fqtr'] = diff_fqtr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b0a529b0-cbf7-4ec5-8f59-fc3ca633a62d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows where diff_fqtr are  NaN: 22\n"
     ]
    }
   ],
   "source": [
    "filtered_df = df[(df['fyr_change_dummy'] == 1) & \n",
    "                 df['cshoq'].isna() & \n",
    "                 df['diff_fqtr'].isna() ]\n",
    "count_both_na = filtered_df.shape[0]\n",
    "print(\"Number of rows where diff_fqtr are  NaN:\", count_both_na)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d99f5cd7-af1b-4047-a2a8-0804a8d20876",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['diff_cshoq'] = df.apply(lambda row: row['below_cshoq'] - row['above_cshoq'] if pd.notna(row['above_cshoq']) and pd.notna(row['below_cshoq']) else np.nan, axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1bc9bcc4-c97b-41a1-8c7e-448de4628c75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows where diff_cshoq are  NaN: 22\n"
     ]
    }
   ],
   "source": [
    "filtered_df = df[(df['fyr_change_dummy'] == 1) & \n",
    "                 df['cshoq'].isna() & \n",
    "                 df['diff_cshoq'].isna() ]\n",
    "count_both_na = filtered_df.shape[0]\n",
    "print(\"Number of rows where diff_cshoq are  NaN:\", count_both_na)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4370a1bd-fece-4be4-b136-a18fad010f01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows where noth above_datafqtr and below_datafqtr are  NaN: 1\n"
     ]
    }
   ],
   "source": [
    "filtered_df = df[(df['fyr_change_dummy'] == 1) & \n",
    "                 df['cshoq'].isna() & \n",
    "                 df['above_datafqtr'].isna() &df['below_datafqtr'].isna()   ]\n",
    "count_both_na = filtered_df.shape[0]\n",
    "print(\"Number of rows where noth above_datafqtr and below_datafqtr are  NaN:\", count_both_na)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "890fd244-c25a-474c-8d71-88c71ba5f990",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          tic  fyr  fqtr   cshoq      prccq     ajexq\n",
      "76626  CHLN.1   12     1  12.076   7.860000  1.000000\n",
      "76627  CHLN.1   12     2  12.076   7.700000  1.000000\n",
      "76628  CHLN.1   12     3  12.078   7.841000  1.000000\n",
      "76629  CHLN.1   12     4  12.076   8.800000  1.000000\n",
      "76630  CHLN.1   12     1  12.083   9.000000  1.000000\n",
      "76631  CHLN.1   12     2  12.096  10.880000  1.000000\n",
      "76632  CHLN.1   12     3  13.478  10.500000  1.000000\n",
      "76633   CHAM.    6     4     NaN   6.250000  1.049999\n",
      "76634   CHAM.    3     1     NaN   8.999999  1.049999\n",
      "76635   CHAM.    3     2     NaN   9.249999  1.049999\n",
      "76636   CHAM.    3     3     NaN  10.624999  1.049999\n",
      "76637   CJHBQ    2     2  34.907   3.750000  0.800000\n",
      "76638   CJHBQ    2     3  34.903   3.500000  0.800000\n",
      "76639   CJHBQ    2     4  35.003   5.875000  0.800000\n",
      "76640   CJHBQ    2     1  35.003   4.125000  0.800000\n"
     ]
    }
   ],
   "source": [
    "df_original = pd.read_csv('/Users/balmeru/Downloads/QQQQ.csv')\n",
    "\n",
    "# Slice the DataFrame to extract rows 76626 to 76640\n",
    "df_subset = df_original.iloc[76626:76641][['tic', 'fyr', 'fqtr', 'cshoq', 'prccq', 'ajexq']]\n",
    "\n",
    "print(df_subset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1e58f41b-c2c3-4e4a-895d-55fa9fb98770",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows where diff_cshoq are not  NaN: 371\n"
     ]
    }
   ],
   "source": [
    "filtered_df = df[(df['fyr_change_dummy'] == 1) & \n",
    "                 df['cshoq'].isna() & \n",
    "                 df['diff_cshoq'].notna() ]\n",
    "count_both_na = filtered_df.shape[0]\n",
    "print(\"Number of rows where diff_cshoq are not  NaN:\", count_both_na)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "345ad09e-c2fe-426a-80d4-c42c4447a623",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            tic  fyr  cshoq  above_cshoq   new_cshoq\n",
      "22        0015B    6    NaN       11.762   11.773500\n",
      "1078      0147A    9    NaN        6.548    6.551500\n",
      "2993      2788A    9    NaN        8.436    8.447000\n",
      "3289      2919B    6    NaN        3.126    3.126000\n",
      "3821      3213B   12    NaN       71.085   71.150000\n",
      "...         ...  ...    ...          ...         ...\n",
      "1071759    WWON   12    NaN       16.330   21.196333\n",
      "1072221  WWWW.1    8    NaN        8.804   36.343333\n",
      "1075104    XL.1   12    NaN      111.804  117.062667\n",
      "1076701   XPRSA   12    NaN       12.086   12.101500\n",
      "1080188    YORK    2    NaN        8.477    8.700667\n",
      "\n",
      "[371 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "df['new_cshoq'] = np.nan\n",
    "\n",
    "# Calculate new_cshoq for rows where fyr_change_dummy is 1, cshoq is NaN, and diff_cshoq and diff_fqtr are not NaN\n",
    "mask = (df['fyr_change_dummy'] == 1) & df['cshoq'].isna() & df['diff_cshoq'].notna() & df['diff_fqtr'].notna()\n",
    "\n",
    "for index, row in df[mask].iterrows():\n",
    "    # Calculate the difference between datafqtr and above_datafqtr\n",
    "    above_year, above_quarter = row['above_datafqtr'].split('Q')\n",
    "    data_year, data_quarter = row['datafqtr'].split('Q')\n",
    "    \n",
    "    above_year = int(above_year)\n",
    "    above_quarter = int(above_quarter)\n",
    "    data_year = int(data_year)\n",
    "    data_quarter = int(data_quarter)\n",
    "    \n",
    "    difference = (data_year - above_year) * 4 + (data_quarter - above_quarter)\n",
    "    \n",
    "    # Calculate new_cshoq value\n",
    "    new_cshoq = row['above_cshoq'] + (row['diff_cshoq'] / row['diff_fqtr']) * difference\n",
    "    \n",
    "    # Update the new_cshoq column with the calculated value\n",
    "    df.at[index, 'new_cshoq'] = new_cshoq\n",
    "\n",
    "print(df[['tic', 'fyr', 'cshoq', 'above_cshoq', 'new_cshoq']][mask])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cb3dd10e-6dfb-44e5-ba25-2947bd130da5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            tic  fyr  cshoq  above_cshoq  below_cshoq  new_cshoq\n",
      "4765      3ACDX   12    NaN        2.100          NaN      2.100\n",
      "37397    3STPHF    9    NaN        3.969          NaN      3.969\n",
      "51322     5841A    9    NaN       85.800          NaN     85.800\n",
      "51545     5853B    6    NaN        2.669          NaN      2.669\n",
      "53821     6103B   12    NaN        3.416          NaN      3.416\n",
      "55474     6733B    1    NaN        8.987          NaN      8.987\n",
      "57620     7556A    6    NaN       16.111          NaN     16.111\n",
      "58716     8550B   12    NaN       56.286          NaN     56.286\n",
      "60530     9901B    8    NaN       15.764          NaN     15.764\n",
      "237388    CGA.1   12    NaN          NaN      312.110    312.110\n",
      "238832     CGNE   12    NaN       60.443          NaN     60.443\n",
      "239820    CHAM.    3    NaN          NaN          NaN        NaN\n",
      "390661      FA1    6    NaN       25.075          NaN     25.075\n",
      "485586      HFO    9    NaN        0.977          NaN      0.977\n",
      "590894    LCNAF    9    NaN       24.731          NaN     24.731\n",
      "591018    LCOR.    9    NaN        1.358          NaN      1.358\n",
      "616441     LXUH    6    NaN        2.885          NaN      2.885\n",
      "631882     MDCA   12    NaN          NaN       12.353     12.353\n",
      "687177     NAB1    9    NaN       43.473          NaN     43.473\n",
      "894971     SKIL    1    NaN       86.250          NaN     86.250\n",
      "1002833   UDS.2    5    NaN        0.965          NaN      0.965\n",
      "1075351     XLL   12    NaN      104.860          NaN    104.860\n"
     ]
    }
   ],
   "source": [
    "# Update new_cshoq for rows where fyr_change_dummy is 1, cshoq is NaN, and above_cshoq or below_cshoq is NaN\n",
    "mask_above_nan = (df['fyr_change_dummy'] == 1) & df['cshoq'].isna() & df['above_cshoq'].isna()\n",
    "mask_below_nan = (df['fyr_change_dummy'] == 1) & df['cshoq'].isna() & df['below_cshoq'].isna()\n",
    "\n",
    "# Set new_cshoq equal to below_cshoq when above_cshoq is NaN\n",
    "df.loc[mask_above_nan, 'new_cshoq'] = df.loc[mask_above_nan, 'below_cshoq']\n",
    "\n",
    "# Set new_cshoq equal to above_cshoq when below_cshoq is NaN\n",
    "df.loc[mask_below_nan, 'new_cshoq'] = df.loc[mask_below_nan, 'above_cshoq']\n",
    "\n",
    "print(df[['tic', 'fyr', 'cshoq', 'above_cshoq', 'below_cshoq', 'new_cshoq']][mask_above_nan | mask_below_nan])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fc42737-7b38-4234-a9ca-844c348e1a7a",
   "metadata": {},
   "source": [
    "### IMPORTANT: I filled in with above or below cshoq wherever either of them was missing!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25340a16-5779-4815-a2df-aa98d8699a6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b33967d-05d9-4a41-bdea-84a32836501a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "847054eb-d4f9-4e3a-866e-ca679b2768d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            tic  fyr       cshoq\n",
      "22        0015B    6   11.773500\n",
      "1078      0147A    9    6.551500\n",
      "2993      2788A    9    8.447000\n",
      "3289      2919B    6    3.126000\n",
      "3821      3213B   12   71.150000\n",
      "...         ...  ...         ...\n",
      "1072221  WWWW.1    8   36.343333\n",
      "1075104    XL.1   12  117.062667\n",
      "1075351     XLL   12  104.860000\n",
      "1076701   XPRSA   12   12.101500\n",
      "1080188    YORK    2    8.700667\n",
      "\n",
      "[393 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# Replace original cshoq values with new_cshoq for rows where fyr_change_dummy is 1 and cshoq is NaN\n",
    "mask_replace_cshoq = (df['fyr_change_dummy'] == 1) & df['cshoq'].isna()\n",
    "\n",
    "# Update cshoq with new_cshoq values\n",
    "df.loc[mask_replace_cshoq, 'cshoq'] = df.loc[mask_replace_cshoq, 'new_cshoq']\n",
    "\n",
    "print(df[['tic', 'fyr', 'cshoq']][mask_replace_cshoq])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2c15b397-2b9b-443e-83ec-b4749ab008c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows where diff_fqtr are  NaN: 1\n"
     ]
    }
   ],
   "source": [
    "filtered_df = df[(df['fyr_change_dummy'] == 1) & \n",
    "                 df['cshoq'].isna()  ]\n",
    "count_both_na = filtered_df.shape[0]\n",
    "print(\"Number of rows where diff_fqtr are  NaN:\", count_both_na)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf17b9b-73cd-427c-b987-76eea38b2081",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad8ad212-3833-4066-a458-b0baa5da7929",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2a6a297e-4c81-4176-bae0-69c56650d623",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['market_cap'] = df['prccq'] / df['ajexq'] * df['cshoq']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4fadd98e-110a-4208-89ac-c127b4d4cfa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate upper and lower bounds\n",
    "df['lower_bound'] = 0.8 * df['market_cap']\n",
    "df['upper_bound'] = 1.2 * df['market_cap']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc7f980-842f-4843-9935-b34bc6324a97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0abedaaf-7ed5-4f32-8ecf-64fc3a872897",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of instances with all empty distances: 31\n",
      "Number of instances with non-empty distances: 2157\n",
      "Number of unique tickers with non-empty distances: 1947\n",
      "Number of unique tickers with all empty distances: 23\n",
      "Number of unique tickers with mixed distances: 8\n",
      "Total number of unique tickers with fiscal year changes: 1978\n"
     ]
    }
   ],
   "source": [
    "df['median_distance'] = np.nan\n",
    "\n",
    "# Ensure the 'median_distance' column is updated for fiscal year change rows\n",
    "df['median_distance'] = np.where(df['fyr_change_dummy'] == 0, np.nan, df['median_distance'])\n",
    "\n",
    "# Initialize variables to count instances with all empty and non-empty distances\n",
    "num_instances_all_empty = 0\n",
    "num_instances_non_empty = 0\n",
    "\n",
    "# Initialize sets to store tickers with non-empty, empty, and mixed distances\n",
    "non_empty_distances_tickers = set()\n",
    "empty_distances_tickers = set()\n",
    "mixed_distances_tickers = set()\n",
    "\n",
    "# Filter rows where fiscal year change occurred\n",
    "fyr_change_rows = df[df['fyr_change_dummy'] == 1]\n",
    "\n",
    "# Iterate over rows where fiscal year change occurred\n",
    "for index, fyr_change_row in fyr_change_rows.iterrows():\n",
    "    # Determine if it's a quarterly or annual report\n",
    "    is_quarterly_report = fyr_change_row['quarterly_report'] == 1\n",
    "\n",
    "    # Filter similar market cap tickers excluding own ticker\n",
    "    similar_cap_tickers = df[(df['market_cap'] >= fyr_change_row['lower_bound']) &\n",
    "                             (df['market_cap'] <= fyr_change_row['upper_bound']) &\n",
    "                             (df['tic'] != fyr_change_row['tic'])]\n",
    "\n",
    "    # Determine relevant distance column and filter criteria\n",
    "    distance_col = 'quarter_distance' if is_quarterly_report else 'annual_distance'\n",
    "    year_col = 'fyearq'\n",
    "    years = [fyr_change_row['fyearq'], fyr_change_row['fyearq'] + 1, fyr_change_row['fyearq'] - 1]\n",
    "\n",
    "    # Extract distances\n",
    "    distances = similar_cap_tickers[similar_cap_tickers[year_col].isin(years)][distance_col].dropna().apply(lambda x: pd.Timedelta(x).days)\n",
    "\n",
    "    # Check if distances list is empty\n",
    "    if distances.empty:\n",
    "        num_instances_all_empty += 1\n",
    "        if fyr_change_row['tic'] in non_empty_distances_tickers:\n",
    "            mixed_distances_tickers.add(fyr_change_row['tic'])\n",
    "        else:\n",
    "            empty_distances_tickers.add(fyr_change_row['tic'])\n",
    "    else:\n",
    "        median_distance = distances.median()\n",
    "        df.loc[index, 'median_distance'] = median_distance\n",
    "        num_instances_non_empty += 1\n",
    "        if fyr_change_row['tic'] in empty_distances_tickers:\n",
    "            mixed_distances_tickers.add(fyr_change_row['tic'])\n",
    "        else:\n",
    "            non_empty_distances_tickers.add(fyr_change_row['tic'])\n",
    "\n",
    "# Calculate counts for unique tickers\n",
    "num_non_empty_distances_tickers = len(non_empty_distances_tickers - mixed_distances_tickers)\n",
    "num_empty_distances_tickers = len(empty_distances_tickers - mixed_distances_tickers)\n",
    "num_mixed_distances_tickers = len(mixed_distances_tickers)\n",
    "num_unique_fyr_change_tickers = fyr_change_rows['tic'].nunique()\n",
    "\n",
    "# Display the results\n",
    "print(f\"Number of instances with all empty distances: {num_instances_all_empty}\")\n",
    "print(f\"Number of instances with non-empty distances: {num_instances_non_empty}\")\n",
    "print(f\"Number of unique tickers with non-empty distances: {num_non_empty_distances_tickers}\")\n",
    "print(f\"Number of unique tickers with all empty distances: {num_empty_distances_tickers}\")\n",
    "print(f\"Number of unique tickers with mixed distances: {num_mixed_distances_tickers}\")\n",
    "print(f\"Total number of unique tickers with fiscal year changes: {num_unique_fyr_change_tickers}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0fce880-509a-4002-b347-a0e4099e621e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c98f758a-9650-4842-a107-5d7b8a8497f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    2157.00\n",
      "mean       90.55\n",
      "std         4.29\n",
      "min        68.00\n",
      "25%        90.00\n",
      "50%        90.00\n",
      "75%        91.00\n",
      "max       132.00\n",
      "Name: median_distance, dtype: object\n"
     ]
    }
   ],
   "source": [
    "summary_stats = df['median_distance'].describe()\n",
    "formatted_stats = summary_stats.apply(lambda x: f'{x:.2f}')\n",
    "\n",
    "print(formatted_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0806ef25-0959-4153-a212-a540b3ae0527",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8f899554-1268-4876-a143-41dc89375f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter rows where fiscal year change occurred\n",
    "fyr_change_rows = df[df['fyr_change_dummy'] == 1]\n",
    "\n",
    "# Iterate over rows where fiscal year change occurred\n",
    "for index, fyr_change_row in fyr_change_rows.iterrows():\n",
    "    # Check if fiscal year change happened in quarterly or annual report\n",
    "    is_quarterly_report = fyr_change_row['quarterly_report'] == 1\n",
    "\n",
    "    # Determine which column to assign median distance\n",
    "    median_distance_column = 'annual_median' if not is_quarterly_report else 'quarterly_median'\n",
    "\n",
    "    # Update the median_distance column accordingly\n",
    "    df.loc[index, median_distance_column] = fyr_change_row['median_distance']\n",
    "\n",
    "# Set NaN for rows where fyr_change_dummy is 0\n",
    "df.loc[df['fyr_change_dummy'] == 0, ['annual_median', 'quarterly_median']] = np.nan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2ac2d930-b0a9-4eea-b52b-68b318917271",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary statistics for Annual Median:\n",
      "count     55.000000\n",
      "mean     115.045455\n",
      "std        6.437213\n",
      "min      101.000000\n",
      "25%      112.000000\n",
      "50%      116.000000\n",
      "75%      119.000000\n",
      "max      132.000000\n",
      "Name: annual_median, dtype: float64\n",
      "\n",
      "Summary statistixcs for Quarterly Median:\n",
      "count    2102.000000\n",
      "mean       89.909134\n",
      "std         1.291728\n",
      "min        68.000000\n",
      "25%        89.500000\n",
      "50%        90.000000\n",
      "75%        91.000000\n",
      "max        96.000000\n",
      "Name: quarterly_median, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "annual_median_summary = df['annual_median'].describe()\n",
    "print(\"Summary statistics for Annual Median:\")\n",
    "print(annual_median_summary)\n",
    "\n",
    "quarterly_median_summary = df['quarterly_median'].describe()\n",
    "print(\"\\nSummary statistixcs for Quarterly Median:\")\n",
    "print(quarterly_median_summary)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5882d3e5-345e-434f-b6a4-e3dc11dea765",
   "metadata": {},
   "source": [
    "#### Overall we have 2188 cases with fyr change. We calculated median distances for 55+2102=2157 cases. \n",
    "#### 411 out of 413 median distances was due to missing market cap. \n",
    "#### 28 cases didn't have prccq when fyr_change_dummy == 1, thus didn't have market cap to be calculated. \n",
    "#### 1 instance didn't have nor above_cshoq or below_cshow to be filled with corresponding or proportionate cshoq. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5eabc50f-0b25-4174-8d9e-95c8af60ef78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28\n"
     ]
    }
   ],
   "source": [
    "# Read the CSV file\n",
    "filtered_df = df[(df['fyr_change_dummy'] == 1) & df['prccq'].isna()]\n",
    "\n",
    "# Select the specific columns\n",
    "filtered_columns_df = filtered_df[['tic', 'fyr', 'fqtr', 'cshoq', 'prccq', 'ajexq']]\n",
    "\n",
    "# Print the filtered DataFrame\n",
    "print(len(filtered_columns_df))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1175c9cf-9a85-4fe1-9ac9-95240ed1e680",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          tic  fyr  fyearq  fqtr      prccq     ajexq   cshoq\n",
      "76626  CHLN.1   12    2003     1   7.860000  1.000000  12.076\n",
      "76627  CHLN.1   12    2003     2   7.700000  1.000000  12.076\n",
      "76628  CHLN.1   12    2003     3   7.841000  1.000000  12.078\n",
      "76629  CHLN.1   12    2003     4   8.800000  1.000000  12.076\n",
      "76630  CHLN.1   12    2004     1   9.000000  1.000000  12.083\n",
      "76631  CHLN.1   12    2004     2  10.880000  1.000000  12.096\n",
      "76632  CHLN.1   12    2004     3  10.500000  1.000000  13.478\n",
      "76633   CHAM.    6    1975     4   6.250000  1.049999     NaN\n",
      "76634   CHAM.    3    1976     1   8.999999  1.049999     NaN\n",
      "76635   CHAM.    3    1976     2   9.249999  1.049999     NaN\n",
      "76636   CHAM.    3    1976     3  10.624999  1.049999     NaN\n",
      "76637   CJHBQ    2    1975     2   3.750000  0.800000  34.907\n",
      "76638   CJHBQ    2    1975     3   3.500000  0.800000  34.903\n",
      "76639   CJHBQ    2    1975     4   5.875000  0.800000  35.003\n",
      "76640   CJHBQ    2    1976     1   4.125000  0.800000  35.003\n"
     ]
    }
   ],
   "source": [
    "df_original = pd.read_csv('/Users/balmeru/Downloads/QQQQ.csv')\n",
    "df_subset = df_original.iloc[76626:76641][['tic', 'fyr', 'fyearq', 'fqtr', 'prccq', 'ajexq', 'cshoq']]\n",
    "print(df_subset)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c64b416-ef41-4c2c-b1e3-1beba01bd2c6",
   "metadata": {},
   "source": [
    "#### Ticker CHAM. didn't have cshoq the entire time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6a03f2f8-0c7f-4b4f-875b-6c896943b3d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             tic  fyr  fqtr   cshoq  prccq   ajexq\n",
      "397147   3CNPIE.   12     1  49.156    NaN  1.0000\n",
      "487345    3CWTVE    6     1     NaN    NaN  0.1000\n",
      "202583    3PRCAE   12     1   4.686    NaN  0.0500\n",
      "47041      8476B   12     1     NaN    NaN  1.0000\n",
      "293327     9975B   12     1  20.420    NaN  1.0000\n",
      "511774   ACCUF.1   12     1  11.247    NaN  1.0000\n",
      "48650     BGI.EC    3     1   1.874    NaN  1.0000\n",
      "761856       CFK   12     1     NaN    NaN  1.0000\n",
      "525687      COES   12     1  45.004    NaN  1.0000\n",
      "89040      CTM.1   12     1   4.418    NaN  1.0000\n",
      "474064      FDRC   12     1     NaN    NaN  1.0000\n",
      "180264      HKAY    9     1     NaN    NaN  1.0000\n",
      "222118      KLRT   11     1     NaN    NaN  2.5000\n",
      "519057     KSEVQ    9     1     NaN    NaN  1.0000\n",
      "99153       KUAL    6     1   7.823    NaN  0.3333\n",
      "610913    LOGO.1   12     1     NaN    NaN  1.0000\n",
      "386795      MNNG    6     1   4.997    NaN  0.0416\n",
      "261535      MSWP   12     1   1.699    NaN  1.0000\n",
      "497110      MWSS   12     1   9.592    NaN  1.0000\n",
      "343675      OLAB   12     1     NaN    NaN  0.2500\n",
      "987235       PCK   12     3  31.997    NaN  1.0000\n",
      "358454     PESXQ    3     1   4.676    NaN  1.0000\n",
      "1081169      SCD   10     2  17.983    NaN  1.0000\n",
      "369272      SIIS   12     1     NaN    NaN  0.4250\n",
      "561304     UBMSQ    8     1  11.281    NaN  0.5000\n",
      "398122     UDS.2   10     1   0.965    NaN  1.0000\n",
      "195781      UHLD    5     1  23.241    NaN  0.2500\n",
      "593668     YES.2    9     1   5.433    NaN  1.5000\n"
     ]
    }
   ],
   "source": [
    "df_original = pd.read_csv('/Users/balmeru/Downloads/QQQQ.csv')\n",
    "df_original['fyr'] = pd.to_numeric(df_original['fyr'], errors='coerce')\n",
    "df_original =df_original.sort_values(by=['tic', 'fyearq', 'fqtr'])\n",
    "ticker_change = df_original['tic'] != df_original['tic'].shift(1)\n",
    "df_original['fyr_change_dummy'] = ((df_original['fyr'] != df_original['fyr'].shift(1)) & (~ticker_change)).astype(int)\n",
    "\n",
    "# Fill the first occurrence of each ticker group with 0\n",
    "df_original.loc[df_original.groupby('tic').head(1).index, 'fyr_change_dummy'] = 0\n",
    "\n",
    "filtered_df = df_original[(df_original['fyr_change_dummy'] == 1) & df_original['prccq'].isna()]\n",
    "filtered_columns_df = filtered_df[['tic', 'fyr', 'fqtr', 'cshoq', 'prccq', 'ajexq']]\n",
    "\n",
    "# Print the filtered DataFrame\n",
    "print(filtered_columns_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7fdd5795-c055-406f-a965-5d07d941502e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28\n"
     ]
    }
   ],
   "source": [
    "print(len(filtered_columns_df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c843f3d7-5ad7-4ab5-8ff2-177f009f24f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            tic  fyearq  fqtr  fyr   cshoq  prccq  ajexq\n",
      "397120    TWSTQ    1989     3    1  23.270  0.125    1.0\n",
      "397121    TWSTQ    1989     4    1  23.290  0.094    1.0\n",
      "397122    TWSTQ    1990     1    1  23.290  0.062    1.0\n",
      "397123    TWSTQ    1990     2    1  23.290  0.031    1.0\n",
      "397124    TWSTQ    1990     3    1  23.290  0.094    1.0\n",
      "397125  3CNPIE.    1983     3    6   3.026  1.875    1.0\n",
      "397126  3CNPIE.    1983     4    6   3.029  1.625    1.0\n",
      "397127  3CNPIE.    1984     1    6   3.063  2.250    1.0\n",
      "397128  3CNPIE.    1984     2    6   3.262  1.625    1.0\n",
      "397129  3CNPIE.    1984     3    6   3.439  1.750    1.0\n",
      "397130  3CNPIE.    1984     4    6   5.005  1.375    1.0\n",
      "397131  3CNPIE.    1985     1    6     NaN  1.750    1.0\n",
      "397132  3CNPIE.    1985     2    6     NaN  1.250    1.0\n",
      "397133  3CNPIE.    1985     3    6     NaN  1.375    1.0\n",
      "397134  3CNPIE.    1985     4    6     NaN  1.375    1.0\n",
      "397135  3CNPIE.    1986     1    6     NaN  0.875    1.0\n",
      "397136  3CNPIE.    1986     2    6     NaN  1.250    1.0\n",
      "397137  3CNPIE.    1986     3    6     NaN  1.125    1.0\n",
      "397138  3CNPIE.    1986     4    6     NaN    NaN    1.0\n",
      "397139  3CNPIE.    1987     1    6     NaN    NaN    1.0\n",
      "397140  3CNPIE.    1987     2    6     NaN    NaN    1.0\n",
      "397141  3CNPIE.    1987     3    6     NaN    NaN    1.0\n",
      "397142  3CNPIE.    1987     4    6     NaN    NaN    1.0\n",
      "397143  3CNPIE.    1988     1    6     NaN    NaN    1.0\n",
      "397144  3CNPIE.    1988     2    6     NaN    NaN    1.0\n",
      "397145  3CNPIE.    1988     3    6     NaN    NaN    1.0\n",
      "397146  3CNPIE.    1988     4    6  49.156    NaN    1.0\n",
      "397147  3CNPIE.    1989     1   12  49.156    NaN    1.0\n",
      "397148  3CNPIE.    1989     2   12  64.013    NaN    1.0\n",
      "397149  3CNPIE.    1989     3   12  64.143    NaN    1.0\n",
      "397150  3CNPIE.    1989     4   12  64.143  0.156    1.0\n",
      "397151  3CNPIE.    1990     1   12  70.810  0.219    1.0\n",
      "397152  3CNPIE.    1990     2   12  70.810  0.125    1.0\n",
      "397153  3CNPIE.    1990     3   12  70.810  0.031    1.0\n",
      "397154  3CNPIE.    1990     4   12  70.810  0.219    1.0\n",
      "397155  3CNPIE.    1991     1   12  70.810  0.312    1.0\n",
      "397156  3CNPIE.    1991     2   12  70.810  0.219    1.0\n",
      "397157  3CNPIE.    1991     3   12  70.810  0.187    1.0\n",
      "397158  3CNPIE.    1991     4   12  70.810  0.125    1.0\n",
      "397159  3CNPIE.    1992     1   12  70.810  0.156    1.0\n",
      "397160  3CNPIE.    1992     2   12  70.810  0.187    1.0\n"
     ]
    }
   ],
   "source": [
    "df_original = pd.read_csv('/Users/balmeru/Downloads/QQQQ.csv')\n",
    "\n",
    "# Print rows 397120 to 397160 from the original DataFrame\n",
    "subset_df = df_original.iloc[397120:397161][['tic', 'fyearq', 'fqtr','fyr',  'cshoq', 'prccq', 'ajexq']]\n",
    "print(subset_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7876d697-532c-4004-b069-8c297b446506",
   "metadata": {},
   "source": [
    "#### As we can see when fyr chnage happened ticker 3CNPIE. didn't have prccq. But some time before or after it did have prccq values.\n",
    "#### We notice price decreased and cshoq increased after fyr change, might be due to stock split. However, I am not sure if we can\n",
    "#### interpolate missing prccqs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b0575e92-a89b-42ed-8e37-3a8de40fb47c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           tic  fyearq  fqtr  fyr  cshoq     prccq  ajexq\n",
      "487335  3CWTVE    1990     1   12   4.40  0.874999    0.1\n",
      "487336  3CWTVE    1990     2   12   4.40  0.749999    0.1\n",
      "487337  3CWTVE    1990     3   12   4.40  0.375000    0.1\n",
      "487338  3CWTVE    1990     4   12   4.40  0.250000    0.1\n",
      "487339  3CWTVE    1991     1   12   4.40  0.250000    0.1\n",
      "487340  3CWTVE    1991     2   12   4.40  0.187000    0.1\n",
      "487341  3CWTVE    1991     3   12    NaN  0.250000    0.1\n",
      "487342  3CWTVE    1991     4   12   4.40       NaN    0.1\n",
      "487343  3CWTVE    1992     1   12    NaN       NaN    0.1\n",
      "487344  3CWTVE    1992     2   12    NaN       NaN    0.1\n",
      "487345  3CWTVE    1993     1    6    NaN       NaN    0.1\n",
      "487346  3CWTVE    1992     3   12    NaN       NaN    0.1\n",
      "487347  3CWTVE    1993     2    6    NaN       NaN    0.1\n",
      "487348  3CWTVE    1992     4   12    NaN       NaN    0.1\n",
      "487349  3CWTVE    1993     3    6    NaN       NaN    0.1\n",
      "487350  3CWTVE    1993     4    6   7.00       NaN    0.1\n",
      "487351  3CWTVE    1994     1    6    NaN       NaN    0.1\n",
      "487352  3CWTVE    1994     2    6    NaN       NaN    0.1\n",
      "487353  3CWTVE    1994     3    6   8.31       NaN    0.1\n",
      "487354  3CWTVE    1994     4    6   4.25  5.249997    0.2\n"
     ]
    }
   ],
   "source": [
    "subset_df = df_original.iloc[487335:487355][['tic', 'fyearq', 'fqtr','fyr',  'cshoq', 'prccq', 'ajexq']]\n",
    "print(subset_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c0284738-7924-4abc-b9ec-e301ed945e13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected rows have been saved to 'with_median_distances.csv'.\n"
     ]
    }
   ],
   "source": [
    "df.to_csv('/Users/balmeru/Downloads/with_median_distances.csv', index=False)\n",
    "\n",
    "print(\"Selected rows have been saved to 'with_median_distances.csv'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "bc644b3c-0109-4ac0-8356-3905ecbe5b73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in the DataFrame (using shape): 1085915\n"
     ]
    }
   ],
   "source": [
    "num_rows_shape = df.shape[0]\n",
    "print(f\"Number of rows in the DataFrame (using shape): {num_rows_shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2baae01-7b2f-4827-9d96-a4ea116d006e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
